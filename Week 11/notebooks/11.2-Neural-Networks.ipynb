{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "Good article of the basics: https://victorzhou.com/blog/intro-to-neural-networks/   \n",
    "Great video of the basics: https://www.youtube.com/watch?v=aircAruvnKk\n",
    "\n",
    "### Introduction to Neural Networks.\n",
    "\"An artificial neural network (or neural network for short) is a predictive model motivated by the way the brain operates. Think of the brain as a collection of neurons wired together. Each neuron looks at the outputs of the other neurons that feed into it, does a calculation, and then either fires (if the calculation exceeds some threshhold) or doesn’t (if it doesn’t).\"   \n",
    "\n",
    "Pretty much the simplest neural network is the perceptron, which approximates a sin‐\n",
    "gle neuron with n binary inputs. It computes a weighted sum of its inputs and “fires”\n",
    "if that weighted sum is zero or greater    \n",
    "(Source: Data Science From Scratch, Chapter 18)\n",
    "\n",
    "![](http://www.saedsayad.com/images/Perceptron_bkp_1.png)\n",
    "\n",
    "\n",
    "\n",
    "The code in the following is adapted from Chapter 18 \"Neural Networks\" in the Data Science from Scratch book. The code can be found at: https://github.com/joelgrus/data-science-from-scratch/blob/master/scratch/neural_networks.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(t):\n",
    "    \"\"\"a step function made continous in order to use calculus (differential)\"\"\"\n",
    "    return 1 / (1 + math.exp(-t)) # t=0 -> 1/2, t=100 -> ~ 1, t=-100 -> ~0\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    \"\"\"reduces all values from input array and weights array to a value between 0 to 1\"\"\"\n",
    "    return sigmoid(dot(weights, inputs)) \n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Trainings Dataset\n",
    "\n",
    "We want to create a Multi-layer Perceptron, which can classifiy -or recognize- the digits from zero to nine for us. In `raw_digits` we create digits consisting out of 5x5 binary pixels. Consequently, each input in our trainings dataset is a binary vector of length 25.\n",
    "\n",
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_digits = [\n",
    "        \"\"\"@@@@@\n",
    "           @...@\n",
    "           @...@\n",
    "           @...@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"..@..\n",
    "           ..@..\n",
    "           ..@..\n",
    "           ..@..\n",
    "           ..@..\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           ....@\n",
    "           @@@@@\n",
    "           @....\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           ....@\n",
    "           @@@@@\n",
    "           ....@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@...@\n",
    "           @...@\n",
    "           @@@@@\n",
    "           ....@\n",
    "           ....@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @....\n",
    "           @@@@@\n",
    "           ....@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @....\n",
    "           @@@@@\n",
    "           @...@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           ....@\n",
    "           ....@\n",
    "           ....@\n",
    "           ....@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @...@\n",
    "           @@@@@\n",
    "           @...@\n",
    "           @@@@@\"\"\",\n",
    "        \"\"\"@@@@@\n",
    "           @...@\n",
    "           @@@@@\n",
    "           ....@\n",
    "           @@@@@\"\"\"]\n",
    "\n",
    "\n",
    "def make_digit(raw_digit):\n",
    "    \"\"\"transform digit set to using zeros instead of dots\"\"\"\n",
    "    return [1 if c == '@' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "\n",
    "\n",
    "inputs = [make_digit(raw_digit) for raw_digit in raw_digits]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create targets as one-hot encoded matrix of 10x10 (each vector has a single one digit at the proper index)\n",
    "targets = [[1 if i == j else 0 for i in range(10)] for j in range(10)]\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed_forward\n",
    "Input is fed to the input neurons, The output from those are fed to the first hidden layers neurons. Then the output from those are fed to the next layer of neurons ... through all the hidden layers till we finally get to the final output layer and get a prediction.\n",
    "\n",
    "\n",
    "\"*Given [the neuron_output] function, we can represent a **neuron** simply as a list of weights whose\n",
    "length is one more than the number of inputs to that neuron (because of the bias\n",
    "weight).  \n",
    "Then we can represent a neural network as a list of (noninput) layers, where\n",
    "each layer is just a list of the neurons in that layer.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network\n",
    "    (represented as a list of lists(non-input layers) of lists(neurons) of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "    outputs = []\n",
    "    # process one layer at a time\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]               # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias)   # compute the output\n",
    "            for neuron in layer]                           # for each neuron\n",
    "        outputs.append(output)                             # and remember it\n",
    "        \n",
    "        # then the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagate\n",
    "How the network get feedback and ajust the weights for each neuron according to the degree of error. Degree of error is calculated with calculus (differential math) to move in the direction where error will minimize. \n",
    "\n",
    "if we have error (y-axis) as a function of neuron weight (x-axis). Then if the slope of the tangent for a particular x value is positive - we move x (the weight) down otherwise move it up.\n",
    "\n",
    "![](https://www.cse.unsw.edu.au/~cs9417ml/MLP2/ErrorPlot.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(network, input_vector, targets):\n",
    "    \"\"\"\n",
    "    1. Run feed_forward on an input vector to produce the outputs of all the neurons\n",
    "    in the network.\n",
    "    2. This results in an error for each output neuron—the difference between its out‐\n",
    "    put and its target.\n",
    "    3. Compute the gradient of this error as a function of the neuron’s weights, and\n",
    "    adjust its weights in the direction that most decreases the error.\n",
    "    4. “Propagate” these output errors backward to infer errors for the hidden layer.\n",
    "    5. Compute the gradients of these errors and adjust the hidden layer’s weights in the\n",
    "    same manner.\n",
    "    \"\"\"\n",
    "    # We assume a single hidden layer from the network given to feed_forward function\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target)\n",
    "                     for output, target in zip(outputs, targets)]\n",
    "    # adjust weights for output layer, one neuron at a time\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        # focus on the ith output layer neuron\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            # adjust the jth weight based on both\n",
    "            # this neuron's delta and its jth input\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                     dot(output_deltas, [n[i] for n in output_layer])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "    # adjust weights for hidden layer, one neuron at a time\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(in_put):\n",
    "    return feed_forward(network, in_put)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/10000 [00:00<00:24, 407.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 389.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(0)   # to get repeatable results\n",
    "input_size = 25  # each input is a vector of length 25 (5x5 \"pixels\")\n",
    "\n",
    "num_hidden = 5   # we'll have 5 neurons in the hidden layer\n",
    "output_size = 10 # we need 10 outputs for each input\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for _ in range(input_size + 1)]\n",
    "                 for _ in range(num_hidden)]\n",
    "#print(hidden_layer)\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for _ in range(num_hidden + 1)]\n",
    "                 for _ in range(output_size)]\n",
    "#print(output_layer)\n",
    "\n",
    "# the network starts out with random weights, one hidden layer and one output layer\n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "# 10,000 iterations seems enough to converge\n",
    "for _ in tqdm(range(10000)):\n",
    "    for input_vector, target_vector in zip(inputs, targets): # inputs is a matrix of 10x25 (ten digits by 25 pixels), target is a one-hot encoded matrix of 10x10 (10 digits by 10 indices where each row has only 1 one and 9 zeroes)\n",
    "        backpropagate(network, input_vector, target_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For convience and reusabilty, we save the vectors containing the raw digits to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      " [1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1]\n",
      " [1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print(np.array(inputs, dtype=np.int8))\n",
    "#np.savetxt?\n",
    "np.savetxt('./simple_digit_trainingset.csv', np.array(inputs, dtype=np.int8), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,1,1,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,1,1,1,1\n",
      "0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0\n",
      "1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1\n",
      "1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1\n",
      "1,0,0,0,1,1,0,0,0,1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1\n",
      "1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1\n",
      "1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1\n",
      "1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1\n",
      "1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1\n",
      "1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat simple_digit_trainingset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We create two helper functions, one for reading our trainings dataset from a file and a second one, which will plot it for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import csv\n",
    "from my_modules import webget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "filename = './simple_digit_trainingset.csv'\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            label = reader.line_num - 1\n",
    "            image = np.array(row[:], dtype=np.int8)\n",
    "            data.append((label, image))\n",
    "    return data\n",
    "\n",
    "def generate_plot(data):\n",
    "    count = 0\n",
    "    f = plt.figure(figsize=(10, 5))\n",
    "    for idx, row in enumerate(data):\n",
    "        imarray = row[1].reshape((5, 5))\n",
    "        plt.subplot(2, 5, idx + 1)\n",
    "        plt.subplots_adjust(hspace=0.5)\n",
    "        count += 1\n",
    "        plt.title('Label = {}'.format(row[0]))\n",
    "        plt.imshow(imarray, cmap='Greys', interpolation='None')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high positive 22026.465794806718\n",
      "1 positive 2.718281828459045\n",
      "0  1.0\n",
      "1 negative 0.01831563888873418\n"
     ]
    }
   ],
   "source": [
    "# Exploring the values of np.exp\n",
    "import numpy as np\n",
    "print('high positive',np.exp(10))\n",
    "print('1 positive',np.exp(1))\n",
    "print('0 ',np.exp(0))\n",
    "print('1 negative',np.exp(-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Test-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0], [0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_testset(data):\n",
    "    count = 0\n",
    "    f = plt.figure(figsize=(10, 5))\n",
    "    data = np.array(data)\n",
    "    for idx, row in enumerate(data):\n",
    "        imarray = row.reshape((5, 5))\n",
    "        plt.subplot(2, len(data), idx + 1)\n",
    "        plt.subplots_adjust(hspace=0.5)\n",
    "        count += 1\n",
    "        plt.imshow(imarray, cmap='Greys', interpolation='None')\n",
    "    return plt\n",
    "\n",
    "\n",
    "test_set = [[0,1,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,0,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,1,1,1,0],\n",
    "            [0,1,1,1,0,\n",
    "             1,0,0,1,1,\n",
    "             0,1,1,1,0,\n",
    "             1,0,0,1,1,\n",
    "             0,1,1,1,0],\n",
    "            [0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0],\n",
    "            [0,1,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0]]\n",
    "print(test_set)\n",
    "plt.show(plot_testset(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [0.   0.01 0.   0.97 0.   0.   0.   0.01 0.   0.1 ]\n",
      "9 [0.   0.   0.   0.   0.   0.58 0.   0.   0.96 1.  ]\n",
      "1 [0.   0.96 0.03 0.02 0.   0.   0.   0.   0.   0.  ]\n",
      "3 [0.   0.14 0.   0.84 0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "for test_data in test_set:\n",
    "    result = predict(test_data)\n",
    "    result = np.array(result)\n",
    "    print(np.argmax(result), np.array_str(result, precision=2, suppress_small=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3 [0.   0.   0.   0.93 0.   0.   0.   0.01 0.   0.1 ]\n",
    "9 [0.   0.   0.   0.   0.   0.54 0.   0.   0.91 1.  ]\n",
    "1 [0.   0.96 0.03 0.02 0.   0.   0.   0.   0.   0.  ]\n",
    "3 [0.   0.22 0.   0.73 0.   0.   0.   0.   0.   0.  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.96 0.   0.   0.   0.   0.   0.   0.02 0.03 0.  ]\n",
      "1 [0.   0.96 0.03 0.02 0.   0.   0.   0.   0.   0.  ]\n",
      "2 [0.   0.02 0.96 0.   0.   0.03 0.   0.   0.   0.  ]\n",
      "3 [0.   0.03 0.   0.97 0.   0.   0.   0.02 0.   0.03]\n",
      "4 [0.   0.02 0.01 0.   0.98 0.   0.   0.   0.   0.  ]\n",
      "5 [0.   0.   0.02 0.   0.   0.96 0.01 0.   0.02 0.01]\n",
      "6 [0.   0.   0.01 0.   0.01 0.01 0.99 0.   0.   0.  ]\n",
      "7 [0.02 0.   0.   0.02 0.   0.   0.   0.97 0.   0.  ]\n",
      "8 [0.04 0.   0.   0.   0.   0.02 0.   0.   0.96 0.03]\n",
      "9 [0.   0.   0.   0.01 0.   0.02 0.   0.   0.03 0.95]\n"
     ]
    }
   ],
   "source": [
    "for test_data in inputs:\n",
    "    result = predict(test_data)\n",
    "    result = np.array(result)\n",
    "    print(np.argmax(result), np.array_str(result, precision=2, suppress_small=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Neural Networks Done Properly...\n",
    "\n",
    "And we still have a bit to go from classifying digits with a Multi-layer Perceptron to a Convolutional Neural Network (CNN), which is the technique used e.g. in IBM's Watson app for visual recognition. \n",
    "\n",
    "A modern framework for implementing various types of neural networks is Google's **Tensorflow**.\n",
    "\n",
    "\n",
    "```bash\n",
    "conda install theano\n",
    "conda install -c conda-forge tensorflow  \n",
    "conda install -c conda-forge keras\n",
    "```\n",
    "\n",
    "You can get more information about it here:\n",
    "\n",
    "  * https://www.youtube.com/watch?v=qyvlt7kiQoI\n",
    "  * https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0\n",
    "  * https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py\n",
    "  * https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist #28x28 handwritten digits\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.34058377 0.55344342 0.51591571 0.47675838 0.16790986 0.06389561\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.90011425 0.75986285 0.82416724 0.80196443 0.71081842 0.42774558\n",
      "  0.31460214 0.29919608 0.35451095 0.35818467 0.34876618 0.33626817\n",
      "  0.34967436 0.335178   0.37058415 0.28257531 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2716561  0.34104081 0.23362221 0.35993679 0.45615513 0.40289729\n",
      "  0.40358052 0.33999555 0.45477668 0.45948942 0.44740712 0.42458103\n",
      "  0.40442136 0.42997581 0.55369632 0.76077969 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03017292\n",
      "  0.10486738 0.02115528 0.11996078 0.1212039  0.11801684 0.10020112\n",
      "  0.03708667 0.39950509 0.55369632 0.57601891 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14658067 0.42828299 0.45560051 0.09781453 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03736313\n",
      "  0.41148549 0.43166863 0.18093226 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21908381\n",
      "  0.44857216 0.40289072 0.0959159  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10392528 0.4228827\n",
      "  0.44857216 0.10495473 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23427223 0.43137432\n",
      "  0.33024801 0.00846409 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01628112 0.3610963  0.42118438\n",
      "  0.10242986 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.2279357  0.44740712 0.30909499\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13428445 0.45406238 0.42274688 0.09680447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02871073 0.39569152 0.45948942 0.29239993 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0047667  0.30675154 0.45477668 0.39617395 0.06165059 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06037819 0.38381719 0.45477668 0.13929404 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05502122\n",
      "  0.35591353 0.38381719 0.20590283 0.00180901 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23605877\n",
      "  0.40358052 0.38381719 0.09310389 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.17070836 0.42952046\n",
      "  0.40358052 0.38381719 0.09310389 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33861822 0.450819\n",
      "  0.40358052 0.330929   0.07161837 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33861822 0.450819\n",
      "  0.32890224 0.02719964 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train,axis=1) # normalize scales all values down to a number between 0 and 1\n",
    "x_test = tf.keras.utils.normalize(x_test,axis=1)\n",
    "plt.imshow(x_test[0])\n",
    "plt.show()\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise with tensorflow and handwritten digits\n",
    "\n",
    "Your task is to extend the above example to work with the 'classical' MNIST dataset, which contains many thousands of handwritten digits. \n",
    "\n",
    "First you should watch the video https://hooktube.com/watch?v=wQ8BIBpya2k, which gives an introduction to Google's Tensorflow - a Python framework helping to build neural networks- and you follow the tutorial on https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist.\n",
    "\n",
    "You have to reproduce their solution and the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Possible Projects:\n",
    "\n",
    "  * Implementation of a Salient Region Detector: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.228.5552&rep=rep1&type=pdf\n",
    "  * Audio Fingerprinting: http://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n",
    "  * Survival on the Titanic: https://www.kaggle.com/c/titanic\n",
    "  * Predict forest cover: https://www.kaggle.com/c/forest-cover-type-prediction\n",
    "  * How to get free pizza: https://www.kaggle.com/c/random-acts-of-pizza"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
