{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow the tutorial from 11.2 Neural network\n",
    "Build and train a model to predict handwritten digits from mnist dataset\n",
    "\n",
    "Great video [here](https://www.youtube.com/watch?v=5qCDzaOUCWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_index = 35\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "(x_train_original, y_train_original), (x_test_original, y_test_original) = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = (x_train_original, y_train_original), (x_test_original, y_test_original)\n",
    "image_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0],image_size)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],image_size)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test out the to_categorical method\n",
    "print(to_categorical([0],10))\n",
    "print(to_categorical([1],10))\n",
    "print(to_categorical([2],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "# model instance\n",
    "model = Sequential()\n",
    "# define each layer in the network\n",
    "from keras.layers import Dense # the simplest layer type\n",
    "\n",
    "input_layer = Dense(units=512,  # 512 units (nodes) is an arbitrary number (might be ajusted later up or down to see what gives most accuracy)\n",
    "                activation='sigmoid', # activation is the activation function used to pass dot product of all inputs and weights through\n",
    "                input_shape=(image_size, )) #28x28 for the mnist image size (must be an iterable, therefore the comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in (image_size,):\n",
    "    print(i)\n",
    "print(len((image_size,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add hidden layer\n",
    "model.add(input_layer)\n",
    "# add another  hidden layer\n",
    "model.add(Dense(units=512,activation='sigmoid'))\n",
    "\n",
    "#model.add(Dense(units=48,activation='relu'))\n",
    "\n",
    "# add an output layer\n",
    "model.add(Dense(units=10, \n",
    "                activation='softmax', # softmax nonlinearity function for mapping the neural network activation to the categories\n",
    "                #input_shape=(image_size,) # does not seem to be warranted\n",
    "               ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 74s 1ms/step - loss: 2.1562 - accuracy: 0.3238 - val_loss: 1.9226 - val_accuracy: 0.4993\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 71s 1ms/step - loss: 1.5141 - accuracy: 0.6547 - val_loss: 1.0805 - val_accuracy: 0.7635\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 72s 1ms/step - loss: 0.9048 - accuracy: 0.7845 - val_loss: 0.6783 - val_accuracy: 0.8502\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 72s 1ms/step - loss: 0.6564 - accuracy: 0.8296 - val_loss: 0.5126 - val_accuracy: 0.8783\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 53s 984us/step - loss: 0.5420 - accuracy: 0.8551 - val_loss: 0.4371 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f83fa907d90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now train the model\n",
    "model.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='sgd', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=5,\n",
    "         verbose=True,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape () for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2cc76be529fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape () for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "ax1.imshow(y_train_original[0], cmap='Greys')\n",
    "ax2.imshow(y_train_original[1], cmap='Greys')\n",
    "ax3.imshow(y_train_original[2], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 718us/step\n",
      "test loss, test acc: [0.48697362561225893, 0.8668000102043152]\n",
      "\n",
      "# Generate predictions for 3 samples\n",
      "predict classes [7 2 1]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(x_test[:3])\n",
    "#print('predictions shape:', predictions.shape)\n",
    "#print(predictions)\n",
    "print('predict classes',model.predict_classes(x_test[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "print(y_train.shape)\n",
    "print('y_train first value',y_train[0])\n",
    "# change the targets to one-hot-encoded\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation here\n",
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using convolutional neural network for image classification with keras\n",
    "https://www.machinecurve.com/index.php/2020/03/30/how-to-use-conv2d-with-keras/#what-are-convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### more complex and more accurate model:\n",
    "\n",
    "\n",
    "# reformat input\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "#reformat output\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model2 = models.Sequential()\n",
    "# keras.layers.Conv2D(filters, kernel_size... filter is how many filters (windows of sub pixel set) kernel is the window size eg: 3x3 pixels\n",
    "model2.add(layers.Conv2D(32, (3,3), activation='relu',input_shape=(28,28,1)))\n",
    "model2.add(layers.MaxPool2D((2,2))) # Max Pooling to reduce the spatial dimensions of the output volume. pool_size: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal)\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu')) # does not need input_shape, since it gets it from previous layer\n",
    "model2.add(layers.MaxPool2D((2,2)))\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model2.add(layers.Flatten()) # rewrite tensor to single vector of values\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='softmax')) # softmax is good for output layer because Softmax outputs probabilities range. The range will 0 to 1, and the sum of all the probabilities will be equal to one. If the softmax function used for multi-classification model it returns the probabilities of each class and the target class will have the high probability.\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 160s 3ms/step - loss: 0.1853 - accuracy: 0.9422 - val_loss: 0.0712 - val_accuracy: 0.9795\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 167s 3ms/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.0356 - val_accuracy: 0.9893\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 176s 3ms/step - loss: 0.0332 - accuracy: 0.9898 - val_loss: 0.0374 - val_accuracy: 0.9910\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 239s 4ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0400 - val_accuracy: 0.9890\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 239s 4ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0335 - val_accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f83d80b7f90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='rmsprop', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "model2.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=5,\n",
    "         verbose=True,\n",
    "         batch_size=64,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s 2ms/step\n",
      "test loss, test acc: [0.02740752196087815, 0.9919000267982483]\n",
      "\n",
      "# Generate predictions for 3 samples\n",
      "[[4.1825419e-12 7.1685019e-10 3.0779002e-09 2.8752992e-10 4.4118029e-15\n",
      "  1.8686053e-12 4.5900087e-19 1.0000000e+00 1.5025502e-11 1.1632210e-09]\n",
      " [2.2818565e-06 2.2877171e-07 9.9999750e-01 7.2858718e-14 5.8374195e-12\n",
      "  7.4479522e-16 4.5182702e-10 8.9414705e-11 3.9628526e-11 2.6583977e-15]\n",
      " [3.2460318e-10 9.9999583e-01 1.4702615e-08 6.5112038e-13 2.1133819e-06\n",
      "  1.3829959e-09 4.5456988e-10 2.0050779e-06 9.8122275e-09 9.2092245e-10]]\n",
      "predict classes [7 2 1]\n",
      "actual:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "results = model2.evaluate(x_test, y_test)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model2.predict(x_test[:3])\n",
    "#print('predictions shape:', predictions.shape)\n",
    "print(predictions)\n",
    "print('predict classes',model2.predict_classes(x_test[:3]))\n",
    "print('actual:\\n',y_test[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
